include:
  - project: 'hive/hive'
    ref: ae61e82b6520e5b78cf85733c414e84a08ca512e #develop
    file: '/scripts/ci-helpers/prepare_data_image_job.yml' 

.prepare_haf_image:
  extends: .docker_image_builder_job

  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR"
    SCRIPTS_PATH: "$SUBMODULE_DIR/scripts"
    REGISTRY_USER: "$CI_IMG_BUILDER_USER"
    REGISTRY_PASS: $CI_IMG_BUILDER_PASSWORD
    BINARY_CACHE_PATH: "hived-binaries"
    HIVE_NETWORK_TYPE: mainnet
  script:
    - $SCRIPTS_PATH/ci-helpers/get_image4submodule.sh
        "$SUBMODULE_DIR" registry.gitlab.syncad.com/hive/haf/ "HAF_IMAGE_NAME" "$REGISTRY_USER" "$REGISTRY_PASS"
        --export-binaries="$BINARY_CACHE_PATH" --network-type="$HIVE_NETWORK_TYPE"
    - ls -la ./$BINARY_CACHE_PATH/*

  artifacts:
    reports:
      dotenv: docker_image_name.env
    paths:
      - ./$BINARY_CACHE_PATH/*
      - ./docker_image_name.env
    expire_in: 6 hours

.prepare_haf_data_5m:
  extends: .docker_image_builder_job

  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR"
    SCRIPTS_PATH: "$SUBMODULE_DIR/scripts"
    BLOCK_LOG_SOURCE_DIR: ""
    CONFIG_INI_SOURCE: ""
    DATA_CACHE_HAF_COMMIT: "${DATA_CACHE_HAF_TEMPLATE}_${HAF_IMAGE_NAME_COMMIT}"
    HIVE_NETWORK_TYPE: mainnet
  script:
    - mkdir "$DATA_CACHE_HAF_COMMIT" -p
    - flock "$DATA_CACHE_HAF_COMMIT" $SCRIPTS_PATH/ci-helpers/build_data.sh $HAF_IMAGE_NAME
        --data-cache="$DATA_CACHE_HAF_COMMIT" --block-log-source-dir="$BLOCK_LOG_SOURCE_DIR" --config-ini-source="$CONFIG_INI_SOURCE"
    - mkdir "$DATA_CACHE_HAF"
    - sudo cp "$DATA_CACHE_HAF_COMMIT"/* "$DATA_CACHE_HAF" -rp
    - cp "$DATA_CACHE_HAF_COMMIT/datadir/docker_entrypoint.log" "$CI_PROJECT_DIR"
    - echo "HIVED_UID=$(id -u)" > hived_uid.env
    - cat hived_uid.env

  artifacts:
    reports:
      dotenv:
        - docker_image_name.env
        - hived_uid.env
    paths:
    - docker_entrypoint.log
    expire_in: 6 hours
