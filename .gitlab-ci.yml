stages:
  - build_and_test

variables:
  FF_NETWORK_PER_BUILD: 0
  GIT_DEPTH: "1"
  GIT_SUBMODULE_STRATEGY: "recursive"
  # uses registry.gitlab.syncad.com/hive/haf/ci-base-image:ubuntu20.04-3
  BUILDER_IMAGE_TAG: "@sha256:a701abca3cdd31bc3a5c7e58a8a2a9ea752e7f30e100aa41bcfe9c56b777883f"
  SETUP_SCRIPTS_PATH: "$CI_PROJECT_DIR/haf/scripts"
  REGISTRY: registry.gitlab.syncad.com/hive/hafah
  HAFAH_IMAGE: $REGISTRY/instance:$CI_COMMIT_SHORT_SHA
  HAFAH_PORT: 6543
  HAF_POSTGRES_URL: postgresql://hive@haf-instance:5432/haf_block_log

include:
  - project: 'hive/haf'
    ref: emf_haf_dockerized_setup_supplement_tests
    file: '/scripts/ci-helpers/prepare_data_image_job.yml'

prepare_haf_image:
  extends: .prepare_haf_data_5m_image
  stage: build_and_test

  tags:
    - public-runner-docker
    - hived-for-tests

prepare_hafah_image:
  extends: .docker_image_builder_job
  stage: build_and_test

  script:
    - docker build --build-arg HTTP_PORT=$HAFAH_PORT --build-arg POSTGRES_URL="$HAF_POSTGRES_URL" --target=instance -t $HAFAH_IMAGE -f Dockerfile . 
    - echo $HAFAH_CI_IMG_BUILDER_PASSWORD | docker login -u $HAFAH_CI_IMG_BUILDER_USER $REGISTRY --password-stdin
    - docker push $HAFAH_IMAGE
  tags:
    - public-runner-docker
    - hived-for-tests

patterns_tests:
  extends: .docker_image_builder_job
  stage: build_and_test
  variables:
    AH_ENDPOINT: hafah_app:$HAFAH_PORT
    FF_NETWORK_PER_BUILD: 0

  needs:
    - job: prepare_hafah_image
    - job: prepare_haf_image
      artifacts: true

  services:
    - name: $HAF_IMAGE_NAME
      alias: haf-instance

    - name: $HAFAH_IMAGE
      alias: hafah_app

  before_script:
    - apk update && apk add bash git ca-certificates curl build-base python3-dev
    - python3 -m ensurepip
    - pip3 install tox

  script:
    - |
      curl --retry 20 --retry-delay 3 --retry-max-time 100 --request POST --url http://haf-instance:8090/ --header 'Content-Type: application/json' --data '{"jsonrpc": "2.0", "method": "call", "params":["database_api","get_version", {} ], "id": 1}'

    # run pattern tests
    - cd $CI_PROJECT_DIR/haf/hive/tests/api_tests
    - ./run_tests.sh $AH_ENDPOINT `git rev-parse --show-toplevel`

    # run comparsion tests
    - export AHRB_PORT=$(cat $CI_PROJECT_DIR/tests/prepare_database/config.ini | grep webserver-http-endpoint | cut -d ':' -f 2)
    - export TJOBS=10
    - cd $CI_PROJECT_DIR/haf/hive/tests/tests_api/hived
    - ./test_ah_enum_virtual_ops.py --ref http://localhost:$AHRB_PORT --test http://$AH_ENDPOINT --start 4900000 --stop 4925000 -d workdir_enum -j $TJOBS
    - ./test_ah_get_ops_in_block.py --ref http://localhost:$AHRB_PORT --test http://$AH_ENDPOINT --start 4900000 --stop 4925000 -d workdir_ops -j $TJOBS
    - ./test_ah_get_account_history.py --ref http://localhost:$AHRB_PORT --test http://$AH_ENDPOINT -f ./input_data/accounts.csv -d workdir_acc -j $TJOBS
    - ./test_ah_get_transaction.py --ref http://localhost:$AHRB_PORT --test http://$AH_ENDPOINT -f ./input_data/hashes.csv -d workdir_trx -j $TJOBS

    # kill hived
    - pkill hived

  artifacts:
    when: always
    reports:
      junit: $CI_PROJECT_DIR/haf/hive/tests/api_tests/results.xml
    paths:
    - "$CI_JOB_NAME"
    - "**/from_node.log"
    - "**/ah.log"
    - "**/*.out.json"
    - "$CI_PROJECT_DIR/haf/hive/tests/tests_api/hived/workdir_*"
    when: always
    expire_in: 6 hours
  tags:
    - public-runner-docker
    - hived-for-tests
